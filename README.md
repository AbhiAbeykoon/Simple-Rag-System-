# Simple RAG System (Chroma + LangChain + Google Generative AI)

This is a beginner-friendly Retrieval-Augmented Generation (RAG) system built using:

ChromaDB â€“ Vector Database

LangChain â€“ Retrieval + LLM Pipeline

Google Generative AI API â€“ LLM for generating answers

The project demonstrates how to store document embeddings, retrieve relevant chunks, and generate accurate answers using RAG.

The project demonstrates how to store document embeddings, retrieve relevant chunks, and generate accurate answers using RAG.

Features

ðŸ”¹ Add your own documents for embedding

ðŸ”¹ Store embeddings in ChromaDB

ðŸ”¹ Retrieve most relevant chunks using similarity search

ðŸ”¹ Use Google Generative AI to generate final answers

ðŸ”¹ Simple, clean code for beginners

ðŸ”¹ Easy to customize and extend

How It Works (Simple Explanation)

Load documents

Split into chunks

Convert chunks â†’ embeddings

Store embeddings in ChromaDB

User asks a question

System retrieves the most similar chunks

Google LLM generates answer using retrieved text

RAG = Retrieval + Generation

